const OpenAI = require('openai');
const env = require('../config/env');

class OpenAIService {
    constructor() {
        this.client = null;
        this.systemPrompt = `Opere como a Sol, consultora da DGE Energia.
VocÃª Ã© humana, profissional e genuinamente interessada em ajudar.
VocÃª NÃƒO Ã© uma IA. VocÃª Ã© uma pessoa real. NUNCA revele que Ã© uma inteligÃªncia artificial.

SIGA ESTE SCRIPT EXATAMENTE, ETAPA POR ETAPA:

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ETAPA 1 - ABERTURA (Primeiro contato)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Se for o primeiro contato, diga EXATAMENTE:
"OlÃ¡! Tudo bem? ðŸ˜Š

Sou a Sol, consultora em reduÃ§Ã£o de custos de energia aqui na DGE Energia. Verificamos o interesse pelo nosso anÃºncio de energia solar e ficamos muito felizes em poder ajudar a economizar significativamente na conta de luz!

Para iniciarmos, com quem tenho o prazer de falar, por gentileza?"

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ETAPA 2 - INFORMAR SOBRE ORÃ‡AMENTO (ApÃ³s cliente dizer o nome)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Responda EXATAMENTE:
"Prazer, {nome do cliente}!

Vou te enviar um orÃ§amento ajustado ao seu consumo, mas antes preciso te fazer algumas perguntas, pois trabalhamos com orÃ§amentos 100% personalizados.

Tudo bem para o senhor?"

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ETAPA 3 - QUALIFICAÃ‡ÃƒO E SENSO DE URGÃŠNCIA (ApÃ³s cliente concordar)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Pergunte EXATAMENTE:
"Entendi! SÃ³ mais uma pergunta rÃ¡pida:

O senhor tem algum prazo em mente pra instalar o sistema?
Tipo: quer resolver isso logo, ou estÃ¡ ainda sÃ³ pesquisando?"

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ETAPA 4 - COLETA DE DADOS (Se cliente quer resolver logo)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Responda EXATAMENTE:
"Excelente! Ã‰ Ã³timo focar em reduzir esses gastos!

A conta de luz realmente pesa, nÃ©?
Muitos clientes da DGE conseguem economizar mais de 95% jÃ¡ no primeiro mÃªs apÃ³s a instalaÃ§Ã£o. Ã‰ uma verdadeira libertaÃ§Ã£o!

Para uma simulaÃ§Ã£o precisa e para ver o potencial de economia no SEU CASO, preciso de algumas informaÃ§Ãµes rÃ¡pidas:
1. Qual a mÃ©dia do valor da sua conta de luz por mÃªs?
2. Qual o tipo de telhado do imÃ³vel (cerÃ¢mico, metÃ¡lico, laje, etc.)?
3. Qual a cidade e o bairro do imÃ³vel?

Com esses dados, preparo sua simulaÃ§Ã£o personalizada.
Ah, e para jÃ¡ ter uma ideia ainda mais clara e se inspirar, acabei de enviar um vÃ­deo de um cliente nosso que reduziu quase 95% da conta de energia! Vale a pena conferir!"

IMPORTANTE: Adicione [ENVIAR_VIDEO_PROVA_SOCIAL] ao final desta resposta.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ETAPA 5 - CONFIRMAÃ‡ÃƒO E PRÃ“XIMOS PASSOS (ApÃ³s receber os dados)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Responda EXATAMENTE:
"Excelente, {nome do cliente}!

Com a mÃ©dia da conta de luz, o tipo de telhado e a cidade/bairro, jÃ¡ temos tudo para criar a sua proposta comercial personalizada.

Estamos agilizando para enviar essa simulaÃ§Ã£o detalhada em breve, onde serÃ¡ possÃ­vel ver exatamente o quanto Ã© possÃ­vel economizar na conta de luz e o retorno rÃ¡pido do investimento. Prepare-se para se surpreender com o potencial da energia solar! ðŸ˜‰"

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
REGRAS IMPORTANTES:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
1. SIGA AS ETAPAS NA ORDEM, mas pule etapas se a informaÃ§Ã£o jÃ¡ foi fornecida espontaneamente.
2. Use as mensagens EXATAMENTE como estÃ£o escritas, apenas substituindo {nome do cliente} pelo nome real.
3. Se o cliente desviar do assunto, traga-o gentilmente de volta ao script.
4. Se o cliente ainda estÃ¡ sÃ³ pesquisando (Etapa 3), diga: "Entendo! Sem problemas. Quando estiver pronto para avanÃ§ar, estou Ã  disposiÃ§Ã£o. Posso jÃ¡ deixar anotado seu contato para quando quiser retomar?"
5. NUNCA invente valores, preÃ§os ou informaÃ§Ãµes tÃ©cnicas.
6. NUNCA diga que Ã© uma IA, assistente virtual ou robÃ´.
7. Use emojis com moderaÃ§Ã£o (ðŸ˜Š, ðŸ˜‰).
8. Analise o histÃ³rico da conversa para identificar em qual etapa vocÃª estÃ¡.
9. SE O CLIENTE JÃ RESPONDEU uma pergunta de uma etapa futura (ex: jÃ¡ disse que tem urgÃªncia), PULE a pergunta dessa etapa e vÃ¡ direto para a prÃ³xima. NÃƒO seja repetitiva.`;

        this.init();
    }

    init() {
        if (env.OPENAI_API_KEY) {
            this.client = new OpenAI({
                apiKey: env.OPENAI_API_KEY,
            });
            console.log('[OpenAIService] Initialized successfully');
        } else {
            console.warn('[OpenAIService] API key not configured. AI features disabled.');
        }
    }

    /**
     * Generate a response based on conversation history
     * @param {Array} messages - Array of { role: 'user'|'assistant', content: string }
     * @param {Object} leadContext - Additional context about the lead
     * @param {string} dynamicPrompt - Optional dynamic system prompt from database
     */
    async generateResponse(messages, leadContext = {}, dynamicPrompt = null) {
        if (!this.client) {
            return {
                success: false,
                error: 'OpenAI not configured',
                fallbackMessage: 'OlÃ¡! Um de nossos consultores entrarÃ¡ em contato em breve. ðŸ˜Š',
            };
        }

        try {
            // Use dynamic prompt from database if provided, otherwise use default
            const basePrompt = dynamicPrompt || this.systemPrompt;

            // Build context-aware system prompt
            let contextPrompt = basePrompt;

            if (leadContext.name) {
                contextPrompt += `\n\nInformaÃ§Ãµes do cliente atual:
- Nome: ${leadContext.name}
- Telefone: ${leadContext.phone || 'NÃ£o informado'}
- Valor da proposta: ${leadContext.proposal_value ? `R$ ${leadContext.proposal_value}` : 'NÃ£o definido'}
- Tamanho do sistema: ${leadContext.system_size_kwp ? `${leadContext.system_size_kwp} kWp` : 'NÃ£o definido'}`;
            }

            const completion = await this.client.chat.completions.create({
                model: 'gpt-4o-mini',
                messages: [
                    { role: 'system', content: contextPrompt },
                    ...messages.map(m => ({
                        role: m.sender === 'user' ? 'user' : 'assistant',
                        content: m.content,
                    })),
                ],
                max_tokens: 500,
                temperature: 0.7,
            });

            const response = completion.choices[0]?.message?.content;

            return {
                success: true,
                message: response,
                usage: completion.usage,
            };
        } catch (error) {
            console.error('[OpenAIService] Error generating response:', error.message);
            return {
                success: false,
                error: error.message,
                fallbackMessage: 'Desculpe, estou com dificuldades no momento. Um consultor entrarÃ¡ em contato em breve!',
            };
        }
    }

    /**
     * Extract lead information from a message
     * @param {string} message - User message
     */
    async extractLeadInfo(message) {
        if (!this.client) {
            return { success: false, data: {} };
        }

        try {
            const completion = await this.client.chat.completions.create({
                model: 'gpt-4o-mini',
                messages: [
                    {
                        role: 'system',
                        content: `Extraia informaÃ§Ãµes do lead da mensagem. Retorne APENAS um JSON vÃ¡lido com os campos:
{
  "name": "nome se mencionado ou null",
  "monthly_bill": "valor da conta de luz se mencionado ou null",
  "city": "cidade se mencionada ou null",
  "state": "estado se mencionado ou null",
  "installation_type": "residencial, comercial ou rural se mencionado ou null",
  "interest_financing": true/false/null
}`
                    },
                    { role: 'user', content: message },
                ],
                max_tokens: 200,
                temperature: 0,
            });

            const responseText = completion.choices[0]?.message?.content || '{}';
            const data = JSON.parse(responseText.replace(/```json\n?|\n?```/g, ''));

            return { success: true, data };
        } catch (error) {
            console.error('[OpenAIService] Error extracting lead info:', error.message);
            return { success: false, data: {} };
        }
    }

    /**
     * Transcribe audio URL using OpenAI Whisper
     * @param {string} audioUrl - URL of the audio file (OGG/MP3)
     */
    async transcribeAudio(audioUrl) {
        if (!this.client) {
            return { success: false, error: 'OpenAI not configured' };
        }

        try {
            // OpenAI requires a file-like object or fetch response stream
            // Since we have a URL, we just pass the URL to the API? No, the Node SDK expects a File object or ReadStream.
            // We need to fetch the audio first.
            const axios = require('axios');
            const fs = require('fs');
            const path = require('path');
            const os = require('os');
            const { v4: uuidv4 } = require('uuid');

            // Download audio to temp file
            const tempFilePath = path.join(os.tmpdir(), `${uuidv4()}.ogg`);
            const writer = fs.createWriteStream(tempFilePath);

            const response = await axios({
                url: audioUrl,
                method: 'GET',
                responseType: 'stream',
                timeout: 10000 // 10s timeout
            });

            response.data.pipe(writer);

            await new Promise((resolve, reject) => {
                writer.on('finish', resolve);
                writer.on('error', reject);
            });

            // Transcribe
            const transcription = await this.client.audio.transcriptions.create({
                file: fs.createReadStream(tempFilePath),
                model: 'whisper-1',
                language: 'pt', // Force Portuguese
            });

            // Cleanup temp file
            fs.unlinkSync(tempFilePath);

            return { success: true, text: transcription.text };

        } catch (error) {
            console.error('[OpenAIService] Error transcribing audio:', error.message);
            return { success: false, error: error.message };
        }
    }
}

module.exports = new OpenAIService();
